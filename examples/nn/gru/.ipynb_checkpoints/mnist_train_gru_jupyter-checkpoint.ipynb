{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c086eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn  # All neural network modules\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment by creating mini batches etc.\n",
    "from tqdm import tqdm  # For a nice progress bar!\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "340f66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = sys.argv[1]\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 28\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "sequence_length = 28\n",
    "learning_rate = 0.005\n",
    "batch_size = 64\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a50b0aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent neural network (many-to-one)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b5a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent neural network with GRU (many-to-one)\n",
    "class RNN_GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN_GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "585c770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent neural network with LSTM (many-to-one)\n",
    "class RNN_LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(\n",
    "            x, (h0, c0)\n",
    "        )  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b35d3f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4f6ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN_GRU(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "model.load_state_dict(torch.load('./saved/minist_gru_model.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adccb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all model layer weights\n",
    "for name, para in model.named_parameters():\n",
    "    print('{}: {}'.format(name, para.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_loader.dataset[0][0].to(device=\"cuda\").squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.dataset[0][0].to(device=\"cuda\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db666cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db768ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dot(y.mean(), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259379da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"torchlogs/\")\n",
    "writer.add_graph(model, x)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b19eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443effe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5bb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e08a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b849713b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10dd46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd1cad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef06f9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "184c4785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru.weight_ih_l0: torch.Size([84, 28])\n",
      "gru.weight_hh_l0: torch.Size([84, 28])\n",
      "gru.bias_ih_l0: torch.Size([84])\n",
      "gru.bias_hh_l0: torch.Size([84])\n",
      "fc.weight: torch.Size([10, 784])\n",
      "fc.bias: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "input_size = 28\n",
    "hidden_size = 28\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "sequence_length = 28\n",
    "learning_rate = 0.005\n",
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "model_mnist_gruNN_028h_01l = RNN_GRU(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "model_mnist_gruNN_028h_01l.load_state_dict(torch.load('./saved/mnist_gruNN_028h_01l.pt'))\n",
    "model_mnist_gruNN_028h_01l.eval()\n",
    "\n",
    "# Display all model layer weights\n",
    "for name, para in model_mnist_gruNN_028h_01l.named_parameters():\n",
    "    print('{}: {}'.format(name, para.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8f4978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save pytorch model to onnx\n",
    "# torch.onnx.export(model_mnist_gruNN_028h_01l,               # model being run\n",
    "#                   x,                         # model input (or a tuple for multiple inputs)\n",
    "#                   \"./saved/model_mnist_gruNN_028h_01l.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "#                   export_params=True,        # store the trained parameter weights inside the model file\n",
    "#                   opset_version=10,          # the ONNX version to export the model to\n",
    "#                   do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "#                   input_names = ['input'],   # the model's input names\n",
    "#                   output_names = ['output'], # the model's output names\n",
    "#                   dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "#                                 'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff2d9803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.4000,  0.1476, -0.0735, -0.4648, -0.0993,  0.1795, -0.3264,  0.0839,\n",
       "         0.1239, -0.2155,  0.2136, -0.0884, -0.2522,  0.1115, -0.5031, -0.2736,\n",
       "        -0.3979,  0.1080, -0.4118, -0.0069, -0.3473, -0.5394, -0.0344,  0.3104,\n",
       "         0.0153, -0.3172, -0.0998, -0.1300,  0.3321,  0.3410, -0.3726,  0.3558,\n",
       "         0.2861,  0.6554,  0.3276,  0.6268, -0.2474,  0.3228,  0.1673,  0.3894,\n",
       "        -0.1630,  0.0657,  0.0359,  0.1218,  0.0825, -0.0739,  0.4201, -0.2237,\n",
       "         0.1578,  0.1416,  0.3530,  0.2813, -0.2020, -0.0252, -0.1244, -0.1051,\n",
       "        -0.0922,  0.1953,  0.2017, -0.0677,  0.0365, -0.5013,  0.1221,  0.2899,\n",
       "         0.2015, -0.1788,  0.0382, -0.1419,  0.1193,  0.0515,  0.2526,  0.4405,\n",
       "         0.0326, -0.0390,  0.2030, -0.0430, -0.1003,  0.0746, -0.3898,  0.0556,\n",
       "         0.0702, -0.1435,  0.1217, -0.1801], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bias_ih_l[k] = the learnable input-hidden bias of the k-th layer (b_ir | b_iz | b_in)\n",
    "model_mnist_gruNN_028h_01l.gru.bias_ih_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "868575c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.3691,  0.0690, -0.0053, -0.1148, -0.2246, -0.0385, -0.2258,  0.2884,\n",
       "         0.1681, -0.3050,  0.1956, -0.0092, -0.1746, -0.0905, -0.5100, -0.4589,\n",
       "        -0.1954,  0.1527, -0.2799, -0.1340, -0.2656, -0.3069,  0.0447,  0.0908,\n",
       "        -0.0516, -0.3764, -0.0749, -0.1740,  0.2364,  0.0821, -0.3590,  0.2619,\n",
       "         0.2211,  0.5693,  0.4157,  0.6016,  0.0998,  0.0400,  0.2538,  0.3113,\n",
       "         0.1467,  0.3964,  0.3508,  0.0704,  0.3375,  0.1091,  0.4836, -0.1224,\n",
       "         0.0752,  0.0085,  0.4005,  0.0710, -0.1148, -0.0090, -0.0796,  0.0179,\n",
       "         0.0616,  0.2382, -0.0596,  0.3472,  0.0390, -0.3615, -0.2248,  0.1447,\n",
       "         0.2577,  0.1948, -0.3932,  0.0247, -0.1228,  0.1300, -0.0088,  0.0054,\n",
       "         0.2527,  0.1980, -0.1795, -0.0170,  0.0184, -0.0293, -0.1308,  0.2345,\n",
       "        -0.1236,  0.1183, -0.1797,  0.0976], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mnist_gruNN_028h_01l.gru.bias_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efde45d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(num_layers, mnist_input\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), hidden_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Forward propagate GRU\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mgru(mnist_input, h0)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "mnist_input = test_loader.dataset[782][0].to(device)\n",
    "# mnist_input = test_loader.dataset[782][0].double().to(device)\n",
    "mnist_input.shape\n",
    "# mnist_input.dtype\n",
    "\n",
    "#torch.save(mnist_input, f\"saved/model_mnist_gruNN_028h_01l_input.pt\")\n",
    "\n",
    "#mnist_input_np = mnist_input.numpy().reshape([28, 28]) #convert to Numpy array\n",
    "#mnist_input_df = pd.DataFrame(mnist_input_np) #convert to a dataframe\n",
    "#mnist_input_df.to_csv(\"./saved/model_mnist_gruNN_028h_01l_input.csv\", index=False, header=False) #save to file\n",
    "\n",
    "#test_np = mnist_input.numpy()\n",
    "#test_np.reshape([28, 28]).shape\n",
    "\n",
    "# self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "# def forward(self, x):\n",
    "h0 = torch.zeros(num_layers, mnist_input.size(0), hidden_size).to(device)\n",
    "# Forward propagate GRU\n",
    "out, _ = model_mnist_gruNN_028h_01l.gru(mnist_input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa7428d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e6e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a2e016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2cf886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd9242c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756bfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53a9751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ec2348",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "sequence_length = 5\n",
    "batch_size = 1\n",
    "\n",
    "smallest_gru_model = nn.GRU(input_size, hidden_size, num_layers)\n",
    "input = torch.randn(sequence_length, batch_size, input_size)\n",
    "h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "output, hn = smallest_gru_model(input, h0)\n",
    "\n",
    "\n",
    "torch.save(smallest_gru_model.state_dict(), f\"saved/the_smallest_gru.pt\")\n",
    "print(f\"The model is saved in ./saved/the_smallest_gru.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb6470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_gru_model = nn.GRU(input_size, hidden_size, num_layers)\n",
    "smallest_gru_model.load_state_dict(torch.load('./saved/the_smallest_gru.pt'))\n",
    "smallest_gru_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5226b22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988c41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c30b631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83740fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, para in smallest_gru_model.named_parameters():\n",
    "    print('{}: {}'.format(name, para.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596fb5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(smallest_gru_model,               # model being run\n",
    "                  input,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"./saved/the_smallest_gru.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af05a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=24)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ac627",
   "metadata": {},
   "outputs": [],
   "source": [
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(input, f\"saved/the_smallest_gru_input.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_test = torch.zeros(sequence_length, batch_size, input_size)\n",
    "input_test = torch.load(f\"saved/the_smallest_gru_input.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b118cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb8484",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_gru_model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_gru_model(input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_gru_model(input[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a88c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_gru_model(input[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9e2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9375173",
   "metadata": {},
   "outputs": [],
   "source": [
    "input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c4efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_gru_model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20953ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_gru_model.weight_ih_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea89b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_gru_model.bias_ih_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f872dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_gru_model.weight_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0545cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "smallest_gru_model.bias_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797bc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
